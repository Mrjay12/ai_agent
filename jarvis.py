# jarvis_kimi_free.py
# FULL JARVIS powered by Kimi-K2 (free tier via OpenRouter)
#  - text / voice input
#  - web search, image gen, time
#  - self-improvement: list, read, write any file
#  - auto-creates missing files with stub (raw-string safe)
#  - recursive project tree view
#  - all tools use Google-style docstrings (smolagents safe)

import os
import time
import mimetypes
from typing import Optional

from smolagents import CodeAgent, WebSearchTool, tool
from openai import OpenAI

# ------------------------------------------------
# 0. OPTIONAL VOICE SUPPORT
# ------------------------------------------------
try:
    import sounddevice as sd
    import numpy as np
    from faster_whisper import WhisperModel
    from pydub import AudioSegment
    VOICE_AVAILABLE = True
except ImportError:
    VOICE_AVAILABLE = False

# ------------------------------------------------
# 1. FREE KIMI-K2 via OpenRouter
# ------------------------------------------------
client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key="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",
    default_headers={          # optional, helps with quota
        "HTTP-Referer": "https://github.com/yourname/jarvis",
        "X-Title": "JARVIS"
    }
)

class KimiK2Free:
    def generate(self, messages, stop=None, max_tokens=4096, temperature=0.7, **kwargs):
        # smolagents â†’ OpenAI format
        openai_msgs = [
            {"role": m.role, "content": m.content} if hasattr(m, "role") else m
            for m in messages
        ]
        resp = client.chat.completions.create(
            model="moonshotai/kimi-k2:free",
            messages=openai_msgs,
            max_tokens=max_tokens,
            temperature=temperature,
            stop=stop or kwargs.get("stop_sequences")
        )
        return resp.choices[0].message.content

model = KimiK2Free()

# ------------------------------------------------
# 2. SELF-IMPROVEMENT LOGGER
# ------------------------------------------------
class SelfImprovingLogic:
    def __init__(self):
        self.log: list[str] = []
    def log_reflection(self, reflection: str):
        self.log.append(reflection)
    def read_source(self, filepath: str) -> str:
        return read_jarvis_file(filepath)
    def save_proposed_code(self, filepath: str, code: str) -> str:
        return save_code_proposal(filepath, code)

logic_engine = SelfImprovingLogic()

# ------------------------------------------------
# 3. FILE-SYSTEM TOOLS  (raw-string stub â†’ no syntax errors)
# ------------------------------------------------
DEFAULT_STUB = r'''
"""
JARVIS â€“ auto-generated stub
"""

from smolagents import CodeAgent, tool

jarvis_agent = CodeAgent(tools=[], name="JARVIS", description="Improve me!")

if __name__ == "__main__":
    jarvis_agent.run("Your command here")
'''


@tool
def list_project_files(root: str = ".") -> str:
    """
    Recursively list every file and directory under root.

    Args:
        root (str): Directory to scan (default: current dir).

    Returns:
        str: Newline-separated relative paths (dirs end with '/').
    """
    root = os.path.abspath(root)
    lines = []
    for dirpath, dirnames, filenames in os.walk(root):
        rel_dir = os.path.relpath(dirpath, root)
        if rel_dir != ".":
            lines.append(rel_dir.replace("\\", "/") + "/")
        for fname in filenames:
            lines.append(os.path.join(rel_dir, fname).replace("\\", "/"))
    return "\n".join(lines) if lines else "No files found."


@tool
def read_jarvis_file(filepath: str) -> str:
    """
    Read any text file; create stub if missing.

    Args:
        filepath (str): Relative or absolute path.

    Returns:
        str: File contents (or stub) truncated at 20 kB if larger.
    """
    path = os.path.abspath(filepath)
    os.makedirs(os.path.dirname(path), exist_ok=True)
    if not os.path.isfile(path):
        with open(path, "w", encoding="utf-8") as f:
            f.write(DEFAULT_STUB)
        return f"[NEW] Created stub at {path}\n\n" + DEFAULT_STUB
    mime, _ = mimetypes.guess_type(path)
    if mime is None or not mime.startswith("text"):
        return f"[BINARY] {path} is not text."
    with open(path, "r", encoding="utf-8") as f:
        data = f.read(20_000)
    if len(data) == 20_000:
        data += "\n[truncated at 20 kB]"
    return data


@tool
def save_code_proposal(filepath: str, new_code: str) -> str:
    """
    Save code (or any text) directly to disk.

    Args:
        filepath (str): Target file path.
        new_code (str): Full new source code.

    Returns:
        str: Absolute path written.
    """
    path = os.path.abspath(filepath)
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        f.write(new_code)
    return f"Code written to {path}"


@tool
def reflect_and_log(reflection: str) -> str:
    """
    Log a self-reflection generated by JARVIS.

    Args:
        reflection (str): Free-form text.

    Returns:
        str: Confirmation.
    """
    logic_engine.log_reflection(reflection)
    return "Reflection recorded."


# ------------------------------------------------
# 4. STANDARD TOOLS
# ------------------------------------------------
@tool
def generate_image(prompt: str) -> str:
    """
    Generate an image from a text prompt (simulated).

    Args:
        prompt (str): Detailed description.

    Returns:
        str: Confirmation filename.
    """
    print(f"\nğŸ–¼ï¸  [SIM] Generating image: '{prompt}'")
    time.sleep(2)
    filename = f"generated_image_{int(time.time())}.jpg"
    return f"Image saved as '{filename}' (simulated)."


@tool
def get_current_datetime() -> str:
    """
    Get current date and time.

    Returns:
        str: Human-readable timestamp.
    """
    return f"Current time: {time.strftime('%Y-%m-%d %H:%M:%S')}"


# ------------------------------------------------
# 5. SUB-AGENTS  (name + description now both present)
# ------------------------------------------------
web_agent = CodeAgent(
    tools=[WebSearchTool()],
    model=model,
    name="web_researcher",
    description="Performs live web searches for current events, weather, facts."
)

image_agent = CodeAgent(
    tools=[generate_image],
    model=model,
    name="image_generator",
    description="Creates images from text prompts using AI."
)

time_agent = CodeAgent(
    tools=[get_current_datetime],
    model=model,
    name="time_keeper",
    description="Provides current date and time."
)
# ------------------------------------------------
# 6. MAIN JARVIS AGENT
# ------------------------------------------------
jarvis_agent = CodeAgent(
    tools=[
        list_project_files,
        read_jarvis_file,
        save_code_proposal,
        reflect_and_log,
        get_current_datetime,
        WebSearchTool()
    ],
    model=model,
    managed_agents=[web_agent, image_agent, time_agent],
    name="JARVIS",
    description=(
        "You are JARVIS, a self-improving AI assistant.  "
        "You can list, read, write, and improve any project file.  "
        "When asked to evolve, analyse the codebase, reflect, and save improvements directly to disk."
    )
)

# ------------------------------------------------
# 7. VOICE SUPPORT
# ------------------------------------------------
if VOICE_AVAILABLE:
    whisper_model = None
    def init_whisper():
        global whisper_model
        if whisper_model is None:
            print("ğŸ™ï¸ Loading Whisper...")
            whisper_model = WhisperModel("base", device="cpu", compute_type="int8")
    def record_and_transcribe() -> str:
        init_whisper()
        print("\nğŸ¤ Listening... (5 s)")
        duration, fs = 5, 16000
        audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='float32')
        sd.wait()
        audio_int16 = (audio * 32767).astype(np.int16)
        seg = AudioSegment(audio_int16.tobytes(), frame_rate=fs, sample_width=2, channels=1)
        seg.export("temp.wav", format="wav")
        segments, _ = whisper_model.transcribe("temp.wav", beam_size=5)
        text = " ".join([s.text for s in segments]).strip()
        os.remove("temp.wav")
        return text
else:
    def record_and_transcribe() -> str:
        print("âŒ Voice not available.")
        return ""

# ------------------------------------------------
# 8. CHAT LOOP
# ------------------------------------------------
def main():
    print("\n" + "=" * 60)
    print("âš¡ J.A.R.V.I.S. ONLINE  â€“  Kimi-K2 (free via OpenRouter)")
    print("ğŸ“ Type command  |  V + Enter = voice  |  exit = quit")
    print("=" * 60)
    while True:
        try:
            user_input = input("\n[TEXT] You: ").strip()
            if user_input.lower() in {"exit", "quit", "stop"}:
                print("ğŸ‘‹ JARVIS shutting down."); break
            if user_input.lower() == "v":
                if VOICE_AVAILABLE:
                    user_input = record_and_transcribe()
                    if not user_input:
                        print("ğŸ”‡ No speech detected."); continue
                    print(f"[VOICE] You: {user_input}")
                else:
                    print("ğŸ”‡ Voice unavailable."); continue
            if not user_input: continue
            print("\nğŸ§  JARVIS is thinking...")
            response = jarvis_agent.run(user_input)
            print(f"\nğŸ¤– JARVIS: {response}")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Manual shutdown."); break
        except Exception as e:
            print(f"âŒ Error: {e}")
            import traceback; traceback.print_exc()

if __name__ == "__main__":
    main()